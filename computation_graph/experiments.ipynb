{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discounting Cashflows with low memory utilization\n",
    "\n",
    "In the lifelib codebase there is code like\n",
    "\n",
    "```py\n",
    "def pv_commissions():\n",
    "    result = np.array(list(commissions(t) for t in range(max_proj_len()))).transpose()\n",
    "    return result @ disc_factors()[:max_proj_len()]\n",
    "```\n",
    "\n",
    "* `result` is shape (Policies, Timesteps)\n",
    "    * Shape (Timesteps, Policies): np.array(list(commissions(t) for t in range(max_proj_len())))\n",
    "    * Shape (Policies, Timesteps): after transposing\n",
    "* `disc_factors()[:max_proj_len()]` is shape (timesteps)\n",
    "\n",
    "This first section discusses if matrix multiplications that allocate an array of (P, T) cashflows are necessary for performant discounting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functools import lru_cache\n",
    "\n",
    "policy_count = 10000\n",
    "policy_term = 20\n",
    "policy_timesteps = 12 * policy_term + 1\n",
    "mortality_rates = np.random.uniform(0, 0.01, size=(policy_timesteps, policy_count))\n",
    "discount_factors = np.linspace(0.99, 0.6, policy_timesteps)\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def pols_if(t):\n",
    "    if t == 0:\n",
    "        return np.ones(policy_count)\n",
    "    return pols_if(t-1) * (1 - mortality_rates[t-1])\n",
    "\n",
    "def pv_matmul():\n",
    "    result = np.array(list(pols_if(t) for t in range(policy_timesteps))).transpose()\n",
    "    return result @ discount_factors\n",
    "\n",
    "def pv_loop():\n",
    "    return sum(pols_if(t) * discount_factors[t] for t in range(policy_timesteps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that doing a loop over the timesteps is faster than a matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.2 ms ± 3.3 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "pv_matmul()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.98 ms ± 194 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "pv_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing BasicTerm_M from O(P*T) to O(P) memory with an LRU cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Cash import cash\n",
    "from lru import LRU\n",
    "from model1 import net_premium_pp as net_premium_pp1, pv_net_cf as pv_net_cf1\n",
    "from model2 import net_premium_pp as net_premium_pp2, pv_net_cf as pv_net_cf2\n",
    "from model3 import net_premium_pp as net_premium_pp3, pv_net_cf as pv_net_cf3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Net premium\n",
    "\n",
    "We would like to minimize cache misses to improve performance, so we do a slight refactor:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code creates two cache misses for each call to `pols_if(t)`\n",
    "```py\n",
    "@cash\n",
    "def net_premium_pp():\n",
    "    return pv_claims() / pv_pols_if()\n",
    "```\n",
    "This code has one cache miss for each call to `pols_if(t)`\n",
    "```py\n",
    "@cash\n",
    "def net_premium_pp():\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    for t in range(max_proj_len):\n",
    "        denominator += pols_if(t) * discount(t)\n",
    "        numerator += claims(t) * discount(t)\n",
    "    return numerator / denominator\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318 ms ± 32.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Cache does not evict\n",
    "cash.reset(dict)\n",
    "net_premium_pp1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440 ms ± 43 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# LRU Cache without code modifications to optimize cache misses\n",
    "cash.reset(lambda: LRU(1))\n",
    "net_premium_pp1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335 ms ± 85.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# LRU Cache with code modifications to optimize cache misses\n",
    "cash.reset(lambda: LRU(1))\n",
    "net_premium_pp2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PV Net CF\n",
    "\n",
    "When using an LRU cache with a max size of 1, logic like this will prevent exponential time blowup, but still causes undesirable cache misses.\n",
    "\n",
    "```py\n",
    "@cash\n",
    "def pv_net_cf():\n",
    "    return pv_premiums() - pv_claims() - pv_expenses() - pv_commissions()\n",
    "```\n",
    "\n",
    "Consider that after we calculate pv_premiums, `pols_if(max_proj_len-1)` will be the only cached value for `pols_if`. When we calculate `pv_claims`, `pv_expenses`, and `pv_commissions`, all calls to `pols_if` will be cache misses.\n",
    "\n",
    "```py\n",
    "...\n",
    "@cash\n",
    "def pv_premiums():\n",
    "    return sum(premiums(t) * discount(t) for t in range(max_proj_len))\n",
    "@cash\n",
    "def pv_claims():\n",
    "    return sum(claims(t) * discount(t) for t in range(max_proj_len))\n",
    "...\n",
    "```\n",
    "\n",
    "See below that the LRU cache causes major performance degradations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515 ms ± 46 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Cache does not evict\n",
    "cash.reset(dict)\n",
    "pv_net_cf1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.16 s ± 82.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# LRU Cache without code modifications to optimize cache misses\n",
    "cash.reset(lambda: LRU(1))\n",
    "pv_net_cf1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can avoid this situation with a slight refactoring - \n",
    "\n",
    "```py\n",
    "@cash\n",
    "def net_cf(t):\n",
    "    return premiums(t) - claims(t) - expenses(t) - commissions(t)\n",
    "@cash\n",
    "def pv_net_cf():\n",
    "    return sum(net_cf(t) * discount(t) for t in range(max_proj_len))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "680 ms ± 130 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# LRU Cache with code modifications to optimize cache misses\n",
    "cash.reset(lambda: LRU(1))\n",
    "pv_net_cf3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The non-evicting cache `cache.reset(dict)` has only one cache miss for each function. The LRU cache even with the optimizations discussed will have two cache misses as two passes are required. One pass for the net premium calculation and one pass for the net cashflows.\n",
    "\n",
    "Despite these cache misses, it is not **twice** as slow, which is was what I was expecting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory utilization\n",
    "\n",
    "The LRU(1) should keep the calculations to $O(P)$ memory complexity, which we expect to reduce memory consumption by a factor of 1000 for models with 1000 timesteps.\n",
    "\n",
    "TODO: Run experiments and get results for actual memory utilization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
